# README: Hackathon SmartDoc.ai

## Equipe 2

Ce projet a √©t√© r√©alis√© dans le cadre du hackathon SmartDoc.ai, ayant pour objectif principal le traitement de documents financiers au format PDF pour en extraire uniquement les contenus pertinents √† l'aide d'outils NLP. Voici une description des √©tapes r√©alis√©es lors des diff√©rentes parties cet exercice.

---
<details>
<summary>Premiere partie (using Google Vision API)</summary>

## 1. Traitement des Donn√©es OCR

### Fonctionnalit√©s Utilis√©es :
La fonction **`produce_brut()`** fournie dans le fichier `helper.py` (que l'on a gard√© comme telle) a √©t√© utilis√©e telle quelle pour transformer les fichiers JSON obtenus √† partir de l'OCR (Google Vision API) en un tableau Excel structurant les blocs textuels extraits des rapports SFCR. Cette fonction constitue la base des analyses effectu√©es dans les √©tapes suivantes.

---

## 2. D√©tection et Lab√©lisation des Contenus

### Objectifs :
L'objectif principal √©tait de classifier automatiquement les blocs textuels extraits des rapports SFCR en trois cat√©gories :
- **Inutile** : Contenus non pertinents comme les bas de page, hauts de page et tableaux.
- **Paragraphe** : Contenus informatifs pertinents pour le corps principal des rapports.
- **Titre** : Grands titres ou sous-titres d√©limitant les diff√©rentes sections des rapports.

### Approche Technique :
Pour cette √©tape, une fonction nomm√©e **`label_content(df, thresholds=None)`** a √©t√© d√©velopp√©e dans le fichier [notebook](google_vision_api/report_cleaning.ipynb). Elle repose sur des seuils d√©finis pour diff√©rencier les cat√©gories de contenu.

#### Fonctionnement de `label_content()` :
1. **Seuils Utilis√©s :**
   - Position verticale (`pos_y`) pour les en-t√™tes et pieds de page.
   - Nombre de caract√®res (`chars`) pour distinguer titres et paragraphes.
   - Taille des caract√®res et hauteur des blocs (`char_size`, `height`) pour identifier le contenu des tableaux.

2. **Classification :** Chaque bloc textuel est √©valu√© selon ces seuils pour √™tre classifi√© en "Inutile", "Titre" ou "Paragraphe". Par exemple :
   - Si la position verticale est proche des bords (haut ou bas de page), il est marqu√© comme "Inutile".
   - Si le nombre de caract√®res est tr√®s faible, il est marqu√© comme "Titre".
   - Si le nombre de caract√®res est √©lev√©, il est consid√©r√© comme "Paragraphe".

### Filtrage et G√©n√©ration des Fichiers Texte :
Une fois la lab√©lisation effectu√©e, les donn√©es inutiles sont filtr√©es pour ne conserver que les titres et paragraphes pertinents. Le contenu r√©sultant est ensuite sauvegard√© dans un fichier texte suivant une organisation claire :
- Les titres et paragraphes sont regroup√©s par page.
- Une ligne de s√©paration est ajout√©e entre les pages pour une meilleure lisibilit√©.

#### Exemple de Code :
Le fichier g√©n√©r√© est produit √† l'aide de la fonction suivante :
```python
# Fonction pour g√©n√©rer un fichier texte organis√©
 def generate_text(dataframe, filename):
     with open(filename, 'w', encoding='utf-8') as f:
         current_page = None
         for _, row in dataframe.iterrows():
             if current_page is None or row['num_page'] != current_page:
                 if current_page is not None:
                     f.write("\n" + "="*50 + "\n")  # S√©parateur pour une nouvelle page
                 current_page = row['num_page']
                 f.write(f"\nPage {current_page}\n")

             if row['Label'] == 'Titre':
                 f.write(f"\n{row['text']}\n")
             elif row['Label'] == 'Paragraphe':
                 f.write(f"{row['text']}\n")

             f.write("\n")
```

### R√©sultats :
- **Classification Automatis√©e :** Les blocs textuels sont correctement identifi√©s et class√©s.
- **Fichiers Lisibles :** Les fichiers texte produits sont clairs et organis√©s par page avec une distinction nette entre les titres et les paragraphes.

### ‚ö†Ô∏è L'on a [ici](google_vision_api/text) 4 fichers `.txt` de l'extraction des 4 [rappors PDF](data/pdfs) 


### Analyse :
La lab√©lisation a √©t√© fait 

---

## Conclusion :
Ces √©tapes ont permis d'√©tablir une base solide pour l'analyse des rapports SFCR en filtrant efficacement le contenu utile. Les techniques de traitement et de lab√©lisation d√©velopp√©es ici pr√©parent √† la deuxi√®me partie de l'exercice, centr√©e sur l'impl√©mentation d'une architecture RAG.

---
## 3. Bonnus : Extraction lisible des informations des tableaux

---
### Objectif  
L'objectif de cette partie √©tait de d√©tecter et extraire automatiquement les tableaux pr√©sents dans des fichiers PDF, puis de convertir leur contenu en texte structur√© tout en pr√©servant la disposition tabulaire. Le code a √©t√© devollop√© dans ce [notebook](tables/table_detection_and_extraction.ipynb)


### √âtapes de la M√©thodologie

1. **D√©tection des Tableaux**  
   - **Mod√®le Utilis√© :** Un mod√®le [YOLOüåê](https://huggingface.co/foduucom/table-detection-and-extraction) a √©t√© employ√© pour d√©tecter les tableaux dans les pages du PDF.  
   - **Processus :** Les pages des PDF sont converties en images. Le mod√®le analyse ces images pour rep√©rer les zones contenant des tableaux et les d√©coupe en sous-images correspondant √† chaque tableau.  
   - **Param√®tres Cl√©s :** Des seuils de confiance (confidence score) et IoU (Intersection over Union) ont √©t√© ajust√©s pour optimiser la pr√©cision de la d√©tection des tableaux.

2. **Extraction des Images des Tableaux**  
   - Une fois d√©tect√©s, les tableaux sont extraits sous forme d'images individuelles et sauvegard√©s dans un r√©pertoire. Chaque image repr√©sente un tableau unique trouv√© dans le document.

3. **Conversion des Images en Texte**  
   - **Outil Utilis√© :** [Tesseract-OCRüåê](https://github.com/tesseract-ocr/tesseract) a √©t√© utilis√© pour convertir le contenu des images en texte lisible et structur√©.  
   - **Pr√©traitement :** Les images des tableaux ont √©t√© redimensionn√©es et converties en RGB pour am√©liorer la qualit√© de l'extraction du texte.  
   - **Structure Conserv√©e :** Une analyse des positions et des blocs textuels a permis de recr√©er la structure tabulaire originale dans le format texte.

4. **R√©sultats Structur√©s**  
   - Le contenu textuel des tableaux est format√© dans des formats exploitables (dans notre cas du texte) pour faciliter les analyses ult√©rieures par les mod√®les.


### R√©sultats  
Cette m√©thodologie a permis :  
- Une d√©tection pr√©cise des tableaux dans des documents PDF complexes.  
- Une extraction fid√®le du contenu tabulaire, avec une pr√©servation de la structure.  
- Une pr√©paration des donn√©es sous une forme facilement exploitable pour des besoins d'analyse ou d'int√©gration.

#### Exemple SFCR [COVEA](data/pdfs/sfcr_covea_2022.PDF) : image d√©tect√©e puis text d√©tect√©

- Apres d√©tection des tables par YOLO (page 89)
![Page 89](images/page_89_apres_YOLO.jpg)

- Apres d√©tection du text dans l'image
![Page 89](images/page_89_apres_Tessaract.png)

### Analyse :
Le mod√®le YOLO permet une detection et extraction syst√©matique sous forme d'image de toutes les tables dans les diff√©rents PDF. La difficult√© apparente se trouve au niveau de l'extraction des tables de ces images (dans le cas de l'utilisation de mod√®le lite non multimodale)

</details>


<details>
<summary>Premiere partie (using  Llama Parser)</summary>

## 1. Exctraction avec  LlamaParse
Vu les limites apparentes de la m√©thode d'extraction avec `Google Vision`, nous avons effectu√© un benchmark qui a abouti √† la solution de `LlamaCloud` : [Llama Parser](https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/). LlamaParse est un parseur de documents sur le march√© sp√©cialement con√ßu pour les am√©liorer les RAG. Cette solution a permis d'extraire de mani√®re fid√®le les informations de divers PDF sous forme de `Markdown`. En utilisant `LlamaParse`, nous avons pu surmonter les d√©fis li√©s √† l'extraction de contenu complexe, tels que les tableaux, les diagrammes et l'ordre de lecture, en obtenant des r√©sultats plus pr√©cis et mieux structur√©s que ceux offerts par les mod√®les multimodaux traditionnels. Gr√¢ce √† son approche hybride, LlamaParse a r√©duit les erreurs d'extraction, tout en offrant une meilleure gestion du contenu visuel et textuel.

### ‚ö†Ô∏è [Code LlamaParse](llama_parser/Hackathon_LlamaParse.ipynb)

## 2. R√©sulats
### ‚ö†Ô∏è L'on a [ici](llama_parser/markdown) 4 fichers `.md` de l'extraction des 4 [rappors PDF](data/pdfs) 

</details>



<details>
<summary>Deuxieme partie</summary>


</details>