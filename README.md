# README: Hackathon SmartDoc.ai

## Equipe 2

Ce projet a √©t√© r√©alis√© dans le cadre du hackathon SmartDoc.ai, ayant pour objectif principal le traitement de documents financiers au format PDF pour en extraire uniquement les contenus pertinents √† l'aide d'outils NLP. Voici une description des √©tapes r√©alis√©es lors des diff√©rentes parties cet exercice.

---
<details>
<summary>Premiere partie (using Google Vision API)</summary>

## 1. Traitement des Donn√©es OCR

### Fonctionnalit√©s Utilis√©es :
La fonction **`produce_brut()`** fournie dans le fichier `helper.py` (que l'on a gard√© comme telle) a √©t√© utilis√©e telle quelle pour transformer les fichiers JSON obtenus √† partir de l'OCR (Google Vision API) en un tableau Excel structurant les blocs textuels extraits des rapports SFCR. Cette fonction constitue la base des analyses effectu√©es dans les √©tapes suivantes.

---

## 2. D√©tection et Lab√©lisation des Contenus

### Objectifs :
L'objectif principal √©tait de classifier automatiquement les blocs textuels extraits des rapports SFCR en trois cat√©gories :
- **Inutile** : Contenus non pertinents comme les bas de page, hauts de page et tableaux.
- **Paragraphe** : Contenus informatifs pertinents pour le corps principal des rapports.
- **Titre** : Grands titres ou sous-titres d√©limitant les diff√©rentes sections des rapports.

### Approche Technique :
Pour cette √©tape, une fonction nomm√©e **`label_content(df, thresholds=None)`** a √©t√© d√©velopp√©e dans le fichier [notebook](google_vision_api/report_cleaning.ipynb). Elle repose sur des seuils d√©finis pour diff√©rencier les cat√©gories de contenu.

#### Fonctionnement de `label_content()` :
1. **Seuils Utilis√©s :**
   - Position verticale (`pos_y`) pour les en-t√™tes et pieds de page.
   - Nombre de caract√®res (`chars`) pour distinguer titres et paragraphes.
   - Taille des caract√®res et hauteur des blocs (`char_size`, `height`) pour identifier le contenu des tableaux.

2. **Classification :** Chaque bloc textuel est √©valu√© selon ces seuils pour √™tre classifi√© en "Inutile", "Titre" ou "Paragraphe". Par exemple :
   - Si la position verticale est proche des bords (haut ou bas de page), il est marqu√© comme "Inutile".
   - Si le nombre de caract√®res est tr√®s faible, il est marqu√© comme "Titre".
   - Si le nombre de caract√®res est √©lev√©, il est consid√©r√© comme "Paragraphe".

### Filtrage et G√©n√©ration des Fichiers Texte :
Une fois la lab√©lisation effectu√©e, les donn√©es inutiles sont filtr√©es pour ne conserver que les titres et paragraphes pertinents. Le contenu r√©sultant est ensuite sauvegard√© dans un fichier texte suivant une organisation claire :
- Les titres et paragraphes sont regroup√©s par page.
- Une ligne de s√©paration est ajout√©e entre les pages pour une meilleure lisibilit√©.

#### Exemple de Code :
Le fichier g√©n√©r√© est produit √† l'aide de la fonction suivante :
```python
# Fonction pour g√©n√©rer un fichier texte organis√©
 def generate_text(dataframe, filename):
     with open(filename, 'w', encoding='utf-8') as f:
         current_page = None
         for _, row in dataframe.iterrows():
             if current_page is None or row['num_page'] != current_page:
                 if current_page is not None:
                     f.write("\n" + "="*50 + "\n")  # S√©parateur pour une nouvelle page
                 current_page = row['num_page']
                 f.write(f"\nPage {current_page}\n")

             if row['Label'] == 'Titre':
                 f.write(f"\n{row['text']}\n")
             elif row['Label'] == 'Paragraphe':
                 f.write(f"{row['text']}\n")

             f.write("\n")
```

### R√©sultats :
- **Classification Automatis√©e :** Les blocs textuels sont correctement identifi√©s et class√©s.
- **Fichiers Lisibles :** Les fichiers texte produits sont clairs et organis√©s par page avec une distinction nette entre les titres et les paragraphes.

### ‚ö†Ô∏è L'on a [ici](google_vision_api/text) 4 fichers `.txt` de l'extraction des 4 [rappors PDF](data/pdfs) 


### Analyse :
La lab√©lisation a √©t√© fait 

---

## Conclusion :
Ces √©tapes ont permis d'√©tablir une base solide pour l'analyse des rapports SFCR en filtrant efficacement le contenu utile. Les techniques de traitement et de lab√©lisation d√©velopp√©es ici pr√©parent √† la deuxi√®me partie de l'exercice, centr√©e sur l'impl√©mentation d'une architecture RAG.

---
## 3. Bonnus : Extraction lisible des informations des tableaux

---
### Objectif  
L'objectif de cette partie √©tait de d√©tecter et extraire automatiquement les tableaux pr√©sents dans des fichiers PDF, puis de convertir leur contenu en texte structur√© tout en pr√©servant la disposition tabulaire. Le code a √©t√© devollop√© dans ce [notebook](tables/table_detection_and_extraction.ipynb)


### √âtapes de la M√©thodologie

1. **D√©tection des Tableaux**  
   - **Mod√®le Utilis√© :** Un mod√®le [YOLOüåê](https://huggingface.co/foduucom/table-detection-and-extraction) a √©t√© employ√© pour d√©tecter les tableaux dans les pages du PDF.  
   - **Processus :** Les pages des PDF sont converties en images. Le mod√®le analyse ces images pour rep√©rer les zones contenant des tableaux et les d√©coupe en sous-images correspondant √† chaque tableau.  
   - **Param√®tres Cl√©s :** Des seuils de confiance (confidence score) et IoU (Intersection over Union) ont √©t√© ajust√©s pour optimiser la pr√©cision de la d√©tection des tableaux.

2. **Extraction des Images des Tableaux**  
   - Une fois d√©tect√©s, les tableaux sont extraits sous forme d'images individuelles et sauvegard√©s dans un r√©pertoire. Chaque image repr√©sente un tableau unique trouv√© dans le document.

3. **Conversion des Images en Texte**  
   - **Outil Utilis√© :** [Tesseract-OCRüåê](https://github.com/tesseract-ocr/tesseract) a √©t√© utilis√© pour convertir le contenu des images en texte lisible et structur√©.  
   - **Pr√©traitement :** Les images des tableaux ont √©t√© redimensionn√©es et converties en RGB pour am√©liorer la qualit√© de l'extraction du texte.  
   - **Structure Conserv√©e :** Une analyse des positions et des blocs textuels a permis de recr√©er la structure tabulaire originale dans le format texte.

4. **R√©sultats Structur√©s**  
   - Le contenu textuel des tableaux est format√© dans des formats exploitables (dans notre cas du texte) pour faciliter les analyses ult√©rieures par les mod√®les.


### R√©sultats  
Cette m√©thodologie a permis :  
- Une d√©tection pr√©cise des tableaux dans des documents PDF complexes.  
- Une extraction fid√®le du contenu tabulaire, avec une pr√©servation de la structure.  
- Une pr√©paration des donn√©es sous une forme facilement exploitable pour des besoins d'analyse ou d'int√©gration.

#### Exemple SFCR [COVEA](data/pdfs/sfcr_covea_2022.PDF) : image d√©tect√©e puis text d√©tect√©

- Apres d√©tection des tables par YOLO (page 89)
![Page 89](images/page_89_apres_YOLO.jpg)

- Apres d√©tection du text dans l'image
![Page 89](images/page_89_apres_Tessaract.png)

### Analyse :
Le mod√®le YOLO permet une detection et extraction syst√©matique sous forme d'image de toutes les tables dans les diff√©rents PDF. La difficult√© apparente se trouve au niveau de l'extraction des tables de ces images (dans le cas de l'utilisation de mod√®le lite non multimodale)

</details>

---
<details>
<summary>Premiere partie (using  Llama Parser)</summary>

## 1. Exctraction avec  LlamaParse
Vu les limites apparentes de la m√©thode d'extraction avec `Google Vision`, nous avons effectu√© un benchmark qui a abouti √† la solution de `LlamaCloud` : [Llama Parser](https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/). LlamaParse est un parseur de documents sur le march√© sp√©cialement con√ßu pour les am√©liorer les RAG. Cette solution a permis d'extraire de mani√®re fid√®le les informations de divers PDF sous forme de `Markdown`. En utilisant `LlamaParse`, nous avons pu surmonter les d√©fis li√©s √† l'extraction de contenu complexe, tels que les tableaux, les diagrammes et l'ordre de lecture, en obtenant des r√©sultats plus pr√©cis et mieux structur√©s que ceux offerts par les mod√®les multimodaux traditionnels. Gr√¢ce √† son approche hybride, LlamaParse a r√©duit les erreurs d'extraction, tout en offrant une meilleure gestion du contenu visuel et textuel.

### ‚ö†Ô∏è [Code LlamaParse](llama_parser/Hackathon_LlamaParse.ipynb)

## 2. R√©sulats
### ‚ö†Ô∏è L'on a [ici](llama_parser/markdown) 4 fichers `.md` de l'extraction des 4 [rappors PDF](data/pdfs) 

</details>


---
<details>
<summary>Deuxieme partie</summary>

## üèóÔ∏è Architecture Technique D√©taill√©e

### Choix du Mod√®le de Langage (LLM)(voir [code](rag_architecture/response.py))

La s√©lection de Google Generative AI (Gemini), et plus particuli√®rement de la version [1.5 Flash](https://ai.google.dev/gemini-api/docs/models/gemini#gemini-1.5-flash), r√©sulte d'une analyse approfondie des besoins sp√©cifiques de notre cas d'usage. Ce mod√®le se distingue par sa capacit√© exceptionnelle √† comprendre et √† traiter des contextes financiers complexes. Sa ma√Ætrise du fran√ßais, combin√©e √† des performances de pointe en analyse de documents techniques, en fait un choix strat√©gique.

Les points forts de Gemini incluent sa capacit√© √† :
- Maintenir la coh√©rence dans l'interpr√©tation de documents longs et techniques
- G√©rer efficacement les nuances du langage financier
- Fournir des r√©ponses structur√©es et professionnelles
- S'adapter rapidement √† diff√©rents styles de rapports financiers

### Strat√©gie Avanc√©e de Chunking(voir [code](rag_architecture/inital_vector.py))

La m√©thode de d√©coupage des documents (chunking) repr√©sente un √©l√©ment crucial de notre architecture RAG. Utilisant RecursiveCharacterTextSplitter, nous avons d√©velopp√© une approche qui va au-del√† du simple d√©coupage m√©canique des documents.

Notre strat√©gie vise √† :
- Pr√©server l'int√©grit√© s√©mantique des sections
- Maintenir un contexte suffisamment large pour une compr√©hension profonde
- Permettre une recherche de similarit√© pr√©cise
- Minimiser la fragmentation des informations cruciales

Avec des chunks de 100 000 caract√®res et un chevauchement de 200 caract√®res, nous garantissons une transition en douceur entre les segments, assurant qu'aucun d√©tail important ne soit perdu lors de l'analyse.

### Vectorisation S√©mantique de Pointe(voir [code](rag_architecture/inital_vector.py))

Le mod√®le d'embedding de Google (`models/embedding-001`) transforme chaque segment de texte en un vecteur math√©matique riche en informations s√©mantiques. Cette transformation permet une recherche de similarit√© qui va bien au-del√† des correspondances litt√©rales, en capturant les nuances et les relations conceptuelles entre diff√©rentes parties du document.

Les avantages de cette approche incluent :
- Une compr√©hension contextuelle profonde
- La capacit√© de relier des concepts financiers apparemment disparates
- Une pr√©cision accrue dans la recherche de segments pertinents

### Moteur de Recherche Vectoriel FAISS(voir [code](rag_architecture/inital_vector.py))

FAISS (Facebook AI Similarity Search) repr√©sente la colonne vert√©brale de notre syst√®me de recherche. Cette biblioth√®que open-source d√©velopp√©e par Facebook permet des recherches de similarit√© ultrarapides, m√™me sur de tr√®s grands ensembles de donn√©es.

Son impl√©mentation nous permet de :
- Indexer rapidement des milliers de pages de rapports financiers
- Effectuer des recherches de similarit√© en quelques millisecondes
- G√©rer efficacement des volumes importants de donn√©es vectoris√©es

## üîç Processus Intelligent de Recherche et G√©n√©ration

Notre cha√Æne de traitement int√®gre plusieurs √©tapes sophistiqu√©es pour garantir des r√©ponses de haute qualit√© :

1. **Pr√©traitement Intelligent**: D√©coupage et vectorisation des documents
2. **Recherche S√©mantique**: Identification des segments les plus pertinents
3. **G√©n√©ration Contextualis√©e**: Production de r√©ponses pr√©cises et professionnelles

Le prompt engineering joue un r√¥le crucial, guidant le mod√®le avec des instructions d√©taill√©es pour :
- Utiliser exclusivement le contexte fourni
- Maintenir une structure de r√©ponse professionnelle
- G√©rer explicitement les cas o√π l'information est incompl√®te ou absente



## üì¶ √âcosyst√®me Technologique

- **Langages**: Python 3.8+
- **Frameworks**: LangChain, Google GenerativeAI
- **Biblioth√®ques**: FAISS, Transformers
- **Infrastructure**: Compatible cloud et environnements locaux

</details>

---
<details>
<summary>Interface Streamlit Chatbot</summary>

# üé• D√©mo de mon projet

Voici une d√©monstration vid√©o :

<iframe src="https://www.loom.com/share/4d81a87a0dec47e982f27d2ec15ecb7b?sid=7aa29e2c-ac09-4e7f-85f9-b1bb8d3f52e0">
</iframe>


</details>